{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "image_to_text.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Sa7Jk3bM1Uh",
        "colab_type": "code",
        "outputId": "96ab8447-1c43-4c03-d6ef-45e5e1eed490",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!pip install flask-ngrok\n",
        "!pip install gluonnlp\n",
        "!pip install mxnet\n",
        "!pip install leven\n",
        "!pip install mxboard\n",
        "!pip install nltk==3.2.5\n",
        "!pip install sacremoses\n",
        "import nltk\n",
        "nltk.download('perluniprops')\n",
        "nltk.download('nonbreaking_prefixes')\n",
        "!pip install PyPDF2\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting flask-ngrok\n",
            "  Downloading https://files.pythonhosted.org/packages/af/6c/f54cb686ad1129e27d125d182f90f52b32f284e6c8df58c1bae54fa1adbc/flask_ngrok-0.0.25-py3-none-any.whl\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from flask-ngrok) (2.21.0)\n",
            "Requirement already satisfied: Flask>=0.8 in /usr/local/lib/python3.6/dist-packages (from flask-ngrok) (1.1.1)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->flask-ngrok) (3.0.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->flask-ngrok) (2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->flask-ngrok) (2019.11.28)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->flask-ngrok) (1.24.3)\n",
            "Requirement already satisfied: Jinja2>=2.10.1 in /usr/local/lib/python3.6/dist-packages (from Flask>=0.8->flask-ngrok) (2.10.3)\n",
            "Requirement already satisfied: click>=5.1 in /usr/local/lib/python3.6/dist-packages (from Flask>=0.8->flask-ngrok) (7.0)\n",
            "Requirement already satisfied: itsdangerous>=0.24 in /usr/local/lib/python3.6/dist-packages (from Flask>=0.8->flask-ngrok) (1.1.0)\n",
            "Requirement already satisfied: Werkzeug>=0.15 in /usr/local/lib/python3.6/dist-packages (from Flask>=0.8->flask-ngrok) (0.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from Jinja2>=2.10.1->Flask>=0.8->flask-ngrok) (1.1.1)\n",
            "Installing collected packages: flask-ngrok\n",
            "Successfully installed flask-ngrok-0.0.25\n",
            "Collecting gluonnlp\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/83/29/c7dffbfc39f8dd8bb9314df7aaf92a67f6c7826ed35d546c8fa63d6e5925/gluonnlp-0.8.3.tar.gz (236kB)\n",
            "\u001b[K     |████████████████████████████████| 245kB 3.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from gluonnlp) (1.17.5)\n",
            "Building wheels for collected packages: gluonnlp\n",
            "  Building wheel for gluonnlp (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gluonnlp: filename=gluonnlp-0.8.3-cp36-none-any.whl size=293539 sha256=0d828efc0e4f81b40eb1ca6804a8a1245f7410bdd6ddfe3d52ab29bcfa713d27\n",
            "  Stored in directory: /root/.cache/pip/wheels/50/6e/32/521aa84da7f9ee725d3c9be0b5e0d771df659bf25da5929f6c\n",
            "Successfully built gluonnlp\n",
            "Installing collected packages: gluonnlp\n",
            "Successfully installed gluonnlp-0.8.3\n",
            "Collecting mxnet\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/92/6c/c6e5562f8face683cec73f5d4d74a58f8572c0595d54f1fed9d923020bbd/mxnet-1.5.1.post0-py2.py3-none-manylinux1_x86_64.whl (25.4MB)\n",
            "\u001b[K     |████████████████████████████████| 25.4MB 1.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy<2.0.0,>1.16.0 in /usr/local/lib/python3.6/dist-packages (from mxnet) (1.17.5)\n",
            "Requirement already satisfied: requests<3,>=2.20.0 in /usr/local/lib/python3.6/dist-packages (from mxnet) (2.21.0)\n",
            "Collecting graphviz<0.9.0,>=0.8.1\n",
            "  Downloading https://files.pythonhosted.org/packages/53/39/4ab213673844e0c004bed8a0781a0721a3f6bb23eb8854ee75c236428892/graphviz-0.8.4-py2.py3-none-any.whl\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.20.0->mxnet) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.20.0->mxnet) (2019.11.28)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.20.0->mxnet) (2.8)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.20.0->mxnet) (1.24.3)\n",
            "Installing collected packages: graphviz, mxnet\n",
            "  Found existing installation: graphviz 0.10.1\n",
            "    Uninstalling graphviz-0.10.1:\n",
            "      Successfully uninstalled graphviz-0.10.1\n",
            "Successfully installed graphviz-0.8.4 mxnet-1.5.1.post0\n",
            "Collecting leven\n",
            "  Downloading https://files.pythonhosted.org/packages/73/02/37084115516cfd595ee2f9a873fffe8b85c6b1538523ff6a8b8dd7ff7d46/leven-1.0.4.tar.gz\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from leven) (1.12.0)\n",
            "Collecting nose\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/15/d8/dd071918c040f50fa1cf80da16423af51ff8ce4a0f2399b7bf8de45ac3d9/nose-1.3.7-py3-none-any.whl (154kB)\n",
            "\u001b[K     |████████████████████████████████| 163kB 5.3MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: leven\n",
            "  Building wheel for leven (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for leven: filename=leven-1.0.4-cp36-cp36m-linux_x86_64.whl size=54679 sha256=40ba4add53655f73668cc04473b6b8b97b7b83deb39f5309be5b97138e409c24\n",
            "  Stored in directory: /root/.cache/pip/wheels/54/64/a5/439db671d666a50f3b3cebd2dcab3fbbab02785adf58e47552\n",
            "Successfully built leven\n",
            "Installing collected packages: nose, leven\n",
            "Successfully installed leven-1.0.4 nose-1.3.7\n",
            "Collecting mxboard\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3e/e4/57f6884c39b471c8fd446dc59998045ceab1c9ebe4a6091c953d97a60934/mxboard-0.1.0-py3-none-any.whl (47kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 1.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from mxboard) (3.10.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from mxboard) (1.17.5)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (from mxboard) (6.2.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from mxboard) (1.12.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.0.0->mxboard) (42.0.2)\n",
            "Installing collected packages: mxboard\n",
            "Successfully installed mxboard-0.1.0\n",
            "Requirement already satisfied: nltk==3.2.5 in /usr/local/lib/python3.6/dist-packages (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk==3.2.5) (1.12.0)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/b4/7a41d630547a4afd58143597d5a49e07bfd4c42914d8335b2a5657efc14b/sacremoses-0.0.38.tar.gz (860kB)\n",
            "\u001b[K     |████████████████████████████████| 870kB 3.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from sacremoses) (2019.12.20)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses) (1.12.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses) (7.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses) (0.14.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from sacremoses) (4.28.1)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.38-cp36-none-any.whl size=884629 sha256=36a881ae4554676b71d312505beed6ca2ddda6520ad733b055d3e2820269e4cb\n",
            "  Stored in directory: /root/.cache/pip/wheels/6d/ec/1a/21b8912e35e02741306f35f66c785f3afe94de754a0eaf1422\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sacremoses\n",
            "Successfully installed sacremoses-0.0.38\n",
            "[nltk_data] Downloading package perluniprops to /root/nltk_data...\n",
            "[nltk_data]   Unzipping misc/perluniprops.zip.\n",
            "[nltk_data] Downloading package nonbreaking_prefixes to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/nonbreaking_prefixes.zip.\n",
            "Collecting PyPDF2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b4/01/68fcc0d43daf4c6bdbc6b33cc3f77bda531c86b174cac56ef0ffdb96faab/PyPDF2-1.26.0.tar.gz (77kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 3.1MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: PyPDF2\n",
            "  Building wheel for PyPDF2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for PyPDF2: filename=PyPDF2-1.26.0-cp36-none-any.whl size=61085 sha256=966cdc5685863228787acd632d5473df8d7a055682a20348a439fcdc6fcbde46\n",
            "  Stored in directory: /root/.cache/pip/wheels/53/84/19/35bc977c8bf5f0c23a8a011aa958acd4da4bbd7a229315c1b7\n",
            "Successfully built PyPDF2\n",
            "Installing collected packages: PyPDF2\n",
            "Successfully installed PyPDF2-1.26.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XsHKKf2SNcvS",
        "colab_type": "code",
        "outputId": "f8012f96-ebff-4997-8080-6a10f7cc51eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A9pl0de8NouI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.chdir('drive/My Drive/Colab Notebooks/models')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T02bvM_ZNx1w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import difflib\n",
        "import importlib\n",
        "import math\n",
        "import cv2 as cv2\n",
        "import numpy as np\n",
        "import mxnet as mx\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import gluonnlp as nlp\n",
        "import leven\n",
        "import matplotlib.patches as patches\n",
        "from skimage import transform as skimage_tf, exposure\n",
        "from tqdm import tqdm\n",
        "from PIL import Image\n",
        "import io\n",
        "import base64\n",
        "import PyPDF2\n",
        "try:\n",
        "    from xml.etree.cElementTree import XML\n",
        "except ImportError:\n",
        "    from xml.etree.ElementTree import XML\n",
        "import zipfile"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UgFFzMWUN_YO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from ocr.utils.expand_bounding_box import expand_bounding_box\n",
        "from ocr.utils.sclite_helper import ScliteHelper\n",
        "from ocr.utils.word_to_line import sort_bbs_line_by_line, crop_line_images\n",
        "from ocr.utils.iam_dataset import IAMDataset, resize_image, crop_image, crop_handwriting_page\n",
        "from ocr.utils.encoder_decoder import Denoiser, ALPHABET, encode_char, decode_char, EOS, BOS\n",
        "from ocr.utils.beam_search import ctcBeamSearch\n",
        "\n",
        "import ocr.utils.denoiser_utils\n",
        "import ocr.utils.beam_search\n",
        "\n",
        "importlib.reload(ocr.utils.denoiser_utils)\n",
        "from ocr.utils.denoiser_utils import SequenceGenerator\n",
        "\n",
        "importlib.reload(ocr.utils.beam_search)\n",
        "from ocr.utils.beam_search import ctcBeamSearch\n",
        "\n",
        "\n",
        "\n",
        "from ocr.paragraph_segmentation_dcnn import SegmentationNetwork, paragraph_segmentation_transform\n",
        "from ocr.word_and_line_segmentation import SSD as WordSegmentationNet, predict_bounding_boxes\n",
        "from ocr.handwriting_line_recognition import Network as HandwritingRecognitionNet, handwriting_recognition_transform\n",
        "from ocr.handwriting_line_recognition import decode as decoder_handwriting, alphabet_encoding\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nYNtOI31etYQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from flask_ngrok import run_with_ngrok\n",
        "from flask import Flask,request,jsonify"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YgOGruK0OAGm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ctx = mx.gpu(0) if mx.context.num_gpus() > 0 else mx.cpu()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "izaJzkwNOD6B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def resize_image(image, desired_size):\n",
        "    ''' Helper function to resize an image while keeping the aspect ratio.\n",
        "    Parameter\n",
        "    ---------\n",
        "    \n",
        "    image: np.array\n",
        "        The image to be resized.\n",
        "\n",
        "    desired_size: (int, int)\n",
        "        The (height, width) of the resized image\n",
        "\n",
        "    Return\n",
        "    ------\n",
        "\n",
        "    image: np.array\n",
        "        The image of size = desired_size\n",
        "\n",
        "    bounding box: (int, int, int, int)\n",
        "        (x, y, w, h) in percentages of the resized image of the original\n",
        "    '''\n",
        "    size = image.shape[:2]\n",
        "    if size[0] > desired_size[0] or size[1] > desired_size[1]:\n",
        "        ratio_w = float(desired_size[0])/size[0]\n",
        "        ratio_h = float(desired_size[1])/size[1]\n",
        "        ratio = min(ratio_w, ratio_h)\n",
        "        new_size = tuple([int(x*ratio) for x in size])\n",
        "        image = cv2.resize(image, (new_size[1], new_size[0]))\n",
        "        size = image.shape\n",
        "            \n",
        "    delta_w = max(0, desired_size[1] - size[1])\n",
        "    delta_h = max(0, desired_size[0] - size[0])\n",
        "    top, bottom = delta_h//2, delta_h-(delta_h//2)\n",
        "    left, right = delta_w//2, delta_w-(delta_w//2)\n",
        "            \n",
        "    color = image[0][0]\n",
        "    if color < 230:\n",
        "        color = 230\n",
        "    image = cv2.copyMakeBorder(image, top, bottom, left, right, cv2.BORDER_CONSTANT, value=float(color))\n",
        "    crop_bb = (left/image.shape[1], top/image.shape[0], (image.shape[1] - right - left)/image.shape[1],\n",
        "               (image.shape[0] - bottom - top)/image.shape[0])\n",
        "    image[image > 230] = 255\n",
        "    return image, crop_bb\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "MAX_IMAGE_SIZE_FORM = (1120, 800)\n",
        "MAX_IMAGE_SIZE_LINE = (60, 800)\n",
        "MAX_IMAGE_SIZE_WORD = (30, 140)\n",
        "\n",
        "\n",
        "#this function takes in the img file path\n",
        "def _pre_process_image(img_in,_parse_method):\n",
        "    #im = cv2.imread(img_in, cv2.IMREAD_GRAYSCALE)\n",
        "    im = img_in\n",
        "    if np.size(im) == 1: # skip if the image data is corrupt.\n",
        "        return None\n",
        "    # reduce the size of form images so that it can fit in memory.\n",
        "    if _parse_method in [\"form\", \"form_bb\"]:\n",
        "        im, _ = resize_image(im, MAX_IMAGE_SIZE_FORM)\n",
        "    if _parse_method == \"line\":\n",
        "        im, _ = resize_image(im, MAX_IMAGE_SIZE_LINE)\n",
        "    if _parse_method == \"word\":\n",
        "        im, _ = resize_image(im, MAX_IMAGE_SIZE_WORD)\n",
        "    img_arr = np.asarray(im)\n",
        "    return img_arr\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2MRCxC4uOPmC",
        "colab_type": "code",
        "outputId": "c6b6349b-386a-4dcc-92c2-c16dfd6556b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "paragraph_segmentation_net = SegmentationNetwork(ctx=ctx)\n",
        "paragraph_segmentation_net.cnn.load_parameters(\"models/paragraph_segmentation2.params\", ctx=ctx)\n",
        "\n",
        "paragraph_segmentation_net.hybridize()    \n",
        "\n",
        "\n",
        "form_size = (1120, 800)\n",
        "def paragraph_segmentation(images):\n",
        "  predicted_bbs = []\n",
        "  for i, image in enumerate(images):\n",
        "    resized_image = paragraph_segmentation_transform(image, form_size)\n",
        "    bb_predicted = paragraph_segmentation_net(resized_image.as_in_context(ctx))\n",
        "    bb_predicted = bb_predicted[0].asnumpy()\n",
        "    bb_predicted = expand_bounding_box(bb_predicted, expand_bb_scale_x=0.03,\n",
        "                                           expand_bb_scale_y=0.03)\n",
        "    predicted_bbs.append(bb_predicted)\n",
        "  return predicted_bbs\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading /root/.mxnet/models/resnet34_v1-48216ba9.zip from https://apache-mxnet.s3-accelerate.dualstack.amazonaws.com/gluon/models/resnet34_v1-48216ba9.zip...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y9irTC6aQimh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "segmented_paragraph_size = (700, 700)\n",
        "\n",
        "def paragraph_segment_crop(images,predicted_bbs):\n",
        "  paragraph_segmented_images = []\n",
        "  for i, image in enumerate(images):\n",
        "    bb = predicted_bbs[i]\n",
        "    image = crop_handwriting_page(image, bb, image_size=segmented_paragraph_size)\n",
        "    paragraph_segmented_images.append(image)\n",
        "  return paragraph_segmented_images\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l8FFdkB0RS_g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word_segmentation_net = WordSegmentationNet(2, ctx=ctx)\n",
        "word_segmentation_net.load_parameters(\"models/word_segmentation2.params\")\n",
        "word_segmentation_net.hybridize()\n",
        "\n",
        "\n",
        "min_c = 0.1\n",
        "overlap_thres = 0.1\n",
        "topk = 600\n",
        "\n",
        "def word_segmentation(paragraph_segmented_images):\n",
        "  predicted_words_bbs_array = []\n",
        "  for i, paragraph_segmented_image in enumerate(paragraph_segmented_images):\n",
        "    predicted_bb = predict_bounding_boxes(\n",
        "        word_segmentation_net, paragraph_segmented_image, min_c, overlap_thres, topk, ctx)\n",
        "\n",
        "    predicted_words_bbs_array.append(predicted_bb)\n",
        "  return predicted_words_bbs_array"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O9JuYxBNTItN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def line_segmentation(predicted_words_bbs_array,paragraph_segmented_images):\n",
        "  line_images_array = []\n",
        "  for i, paragraph_segmented_image in enumerate(paragraph_segmented_images):\n",
        "    predicted_bbs = predicted_words_bbs_array[i]\n",
        "    line_bbs = sort_bbs_line_by_line(predicted_bbs, y_overlap=0.4)\n",
        "    line_images = crop_line_images(paragraph_segmented_image, line_bbs)\n",
        "    line_images_array.append(line_images)\n",
        "  return line_images_array"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HRsFG6-mUdhl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "handwriting_line_recognition_net = HandwritingRecognitionNet(rnn_hidden_states=512,\n",
        "                                                             rnn_layers=2, ctx=ctx, max_seq_len=160)\n",
        "handwriting_line_recognition_net.load_parameters(\"models/handwriting_line8.params\", ctx=ctx)\n",
        "handwriting_line_recognition_net.hybridize()\n",
        "\n",
        "\n",
        "line_image_size = (60, 800)\n",
        "\n",
        "def handwriting_line_recognition(line_images_array):\n",
        "  character_probs = []\n",
        "  for line_images in line_images_array:\n",
        "    form_character_prob = []\n",
        "    for i, line_image in enumerate(line_images):\n",
        "        line_image = handwriting_recognition_transform(line_image, line_image_size)\n",
        "        line_character_prob = handwriting_line_recognition_net(line_image.as_in_context(ctx))\n",
        "        form_character_prob.append(line_character_prob)\n",
        "    character_probs.append(form_character_prob)\n",
        "  return character_probs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WiIB2Y2NVBD3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_arg_max(prob):\n",
        "    '''\n",
        "    The greedy algorithm convert the output of the handwriting recognition network\n",
        "    into strings.\n",
        "    '''\n",
        "    arg_max = prob.topk(axis=2).asnumpy()\n",
        "    return decoder_handwriting(arg_max)[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cWkiTRT0VQuu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def decode_line(character_probs):\n",
        "  decoded_images = {}\n",
        "  for i, form_character_probs in enumerate(character_probs):\n",
        "    text = []\n",
        "    for j, line_character_probs in enumerate(form_character_probs):\n",
        "      decoded_line_am = get_arg_max(line_character_probs)\n",
        "      text.append(decoded_line_am)\n",
        "    text = ','.join(text)\n",
        "    decoded_images.update({i:text})\n",
        "  return decoded_images"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "abknKuPZi2-Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def decode_images(images):\n",
        "  decoded = []\n",
        "  for image in images:\n",
        "    imgdata = base64.b64decode(image)\n",
        "    image = Image.open(io.BytesIO(imgdata))\n",
        "    image = cv2.cvtColor(np.array(image), cv2.COLOR_BGR2RGB)\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    decoded.append(image)\n",
        "  return decoded"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bAdWl4BrWkb2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def pdfToText(myfile):\n",
        "  #print(myPdf.numPages)\n",
        "  myPdf = PyPDF2.PdfFileReader(myfile)\n",
        "  num_pages = myPdf.numPages\n",
        "  count = 0\n",
        "  text = \"\"\n",
        "  while count < num_pages:\n",
        "    pageObj = myPdf.getPage(count)\n",
        "    count +=1\n",
        "    text += pageObj.extractText()\n",
        "  #print(text)\n",
        "  return text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E20SSOt7WrKZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def decode(encoded):\n",
        "  decoded = []\n",
        "  for pdf in encoded:\n",
        "    pdf = base64.b64decode(pdf)\n",
        "    pdf = io.BytesIO(pdf)\n",
        "    decoded.append(pdf)\n",
        "  return decoded"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7m_U--XHWupe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "WORD_NAMESPACE = '{http://schemas.openxmlformats.org/wordprocessingml/2006/main}'\n",
        "PARA = WORD_NAMESPACE + 'p'\n",
        "TEXT = WORD_NAMESPACE + 't'\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3lHje-xKWxpm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_docx_text(doc):\n",
        "    document = zipfile.ZipFile(doc)\n",
        "    xml_content = document.read('word/document.xml')\n",
        "    document.close()\n",
        "    tree = XML(xml_content)\n",
        "\n",
        "    paragraphs = []\n",
        "    for paragraph in tree.getiterator(PARA):\n",
        "        texts = [node.text\n",
        "                 for node in paragraph.getiterator(TEXT)\n",
        "                 if node.text]\n",
        "        if texts:\n",
        "            paragraphs.append(''.join(texts))\n",
        "\n",
        "    return '\\n\\n'.join(paragraphs)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_mf8zmF4cfyW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "app = Flask(__name__)\n",
        "run_with_ngrok(app)\n",
        "@app.route('/image-text/<uuid>',methods = ['POST','GET'])\n",
        "def home(uuid):\n",
        "  content = request.get_json(force=True)\n",
        "  #print(content)\n",
        "  images = content[\"images\"]\n",
        "  images_decoded = decode_images(images)\n",
        "  processed = []\n",
        "  for image in images_decoded:\n",
        "    image = _pre_process_image(image,'form')\n",
        "    processed.append(image)\n",
        "  random.seed(1)\n",
        "  predicted_bbs = paragraph_segmentation(processed)\n",
        "  paragraph_segmented_images = paragraph_segment_crop(images = processed,predicted_bbs= predicted_bbs)\n",
        "  predicted_words_bbs_array = word_segmentation(paragraph_segmented_images = paragraph_segmented_images)\n",
        "  line_images_array = line_segmentation(predicted_words_bbs_array = predicted_words_bbs_array, paragraph_segmented_images = paragraph_segmented_images)\n",
        "  character_probs = handwriting_line_recognition(line_images_array= line_images_array)\n",
        "  decoded_images = decode_line(character_probs = character_probs)\n",
        "  return jsonify({\"uuid\" : uuid, \"text\" : decoded_images})\n",
        "@app.route('/pdf-text/<uuid>',methods = ['POST'])\n",
        "def pdf_text(uuid):\n",
        "  content = request.get_json(force=True)\n",
        "  pdfs = content[\"pdfs\"]\n",
        "  pdfs_decoded = decode(pdfs)\n",
        "  texts = {}\n",
        "  i = 0\n",
        "  for pdf in pdfs_decoded:\n",
        "    pdf_converted = pdfToText(pdf)\n",
        "    texts.update({i:pdf_converted})\n",
        "    i = i+1\n",
        "  return jsonify({\"uuid\":uuid,\"text\":texts})\n",
        "@app.route('/word-text/<uuid>',methods = ['POST'])\n",
        "def word_text(uuid):\n",
        "  content = request.get_json(force=True)\n",
        "  #print(content)\n",
        "  docs = content[\"docs\"]\n",
        "  docs_decoded = decode(docs)\n",
        "  texts = {}\n",
        "  i = 0\n",
        "  for doc in docs_decoded:\n",
        "    doc_converted = get_docx_text(doc)\n",
        "    texts.update({i:doc_converted})\n",
        "    i = i+1\n",
        "  return jsonify({\"uuid\":uuid,\"text\":texts})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jybcSjJ8hKXA",
        "colab_type": "code",
        "outputId": "47350315-ce3a-443e-c60b-0f5036153207",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "app.run()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " * Serving Flask app \"__main__\" (lazy loading)\n",
            " * Environment: production\n",
            "   WARNING: This is a development server. Do not use it in a production deployment.\n",
            "   Use a production WSGI server instead.\n",
            " * Debug mode: off\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:werkzeug: * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " * Running on http://c3551dd3.ngrok.io\n",
            " * Traffic stats available on http://127.0.0.1:4040\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [23/Jan/2020 03:52:30] \"\u001b[33mGET / HTTP/1.1\u001b[0m\" 404 -\n",
            "INFO:werkzeug:127.0.0.1 - - [23/Jan/2020 03:57:26] \"\u001b[37mPOST /pdf-text/123 HTTP/1.1\u001b[0m\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [23/Jan/2020 04:07:25] \"\u001b[37mPOST /pdf-text/123 HTTP/1.1\u001b[0m\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [23/Jan/2020 04:11:52] \"\u001b[37mPOST /pdf-text/123 HTTP/1.1\u001b[0m\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [23/Jan/2020 04:13:30] \"\u001b[37mPOST /pdf-text/123 HTTP/1.1\u001b[0m\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [23/Jan/2020 04:14:14] \"\u001b[37mPOST /pdf-text/123 HTTP/1.1\u001b[0m\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [23/Jan/2020 04:14:53] \"\u001b[37mPOST /pdf-text/123 HTTP/1.1\u001b[0m\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [23/Jan/2020 04:15:27] \"\u001b[37mPOST /pdf-text/123 HTTP/1.1\u001b[0m\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [23/Jan/2020 04:17:09] \"\u001b[37mPOST /pdf-text/123 HTTP/1.1\u001b[0m\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [23/Jan/2020 04:18:08] \"\u001b[37mPOST /pdf-text/123 HTTP/1.1\u001b[0m\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [23/Jan/2020 04:20:31] \"\u001b[37mPOST /pdf-text/123 HTTP/1.1\u001b[0m\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [23/Jan/2020 04:22:50] \"\u001b[37mPOST /pdf-text/123 HTTP/1.1\u001b[0m\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [23/Jan/2020 04:23:23] \"\u001b[37mPOST /pdf-text/123 HTTP/1.1\u001b[0m\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [23/Jan/2020 04:26:30] \"\u001b[1m\u001b[31mPOST /pdf-text/123 HTTP/1.1\u001b[0m\" 400 -\n",
            "INFO:werkzeug:127.0.0.1 - - [23/Jan/2020 04:26:44] \"\u001b[37mPOST /pdf-text/123 HTTP/1.1\u001b[0m\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [23/Jan/2020 04:28:28] \"\u001b[37mPOST /pdf-text/123 HTTP/1.1\u001b[0m\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [23/Jan/2020 04:29:05] \"\u001b[37mPOST /pdf-text/123 HTTP/1.1\u001b[0m\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [23/Jan/2020 04:31:30] \"\u001b[37mPOST /pdf-text/123 HTTP/1.1\u001b[0m\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [23/Jan/2020 04:36:16] \"\u001b[37mPOST /pdf-text/123 HTTP/1.1\u001b[0m\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [23/Jan/2020 04:42:30] \"\u001b[37mPOST /pdf-text/123 HTTP/1.1\u001b[0m\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [23/Jan/2020 04:43:12] \"\u001b[37mPOST /pdf-text/123 HTTP/1.1\u001b[0m\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [23/Jan/2020 04:43:22] \"\u001b[37mPOST /pdf-text/123 HTTP/1.1\u001b[0m\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [23/Jan/2020 04:44:50] \"\u001b[37mPOST /pdf-text/123 HTTP/1.1\u001b[0m\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [23/Jan/2020 04:46:19] \"\u001b[37mPOST /pdf-text/123 HTTP/1.1\u001b[0m\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [23/Jan/2020 04:47:03] \"\u001b[37mPOST /pdf-text/123 HTTP/1.1\u001b[0m\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [23/Jan/2020 04:47:15] \"\u001b[37mPOST /pdf-text/123 HTTP/1.1\u001b[0m\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [23/Jan/2020 04:49:08] \"\u001b[37mPOST /word-text/123 HTTP/1.1\u001b[0m\" 200 -\n",
            "ERROR:__main__:Exception on /word-text/123 [POST]\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/flask/app.py\", line 2446, in wsgi_app\n",
            "    response = self.full_dispatch_request()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/flask/app.py\", line 1951, in full_dispatch_request\n",
            "    rv = self.handle_user_exception(e)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/flask/app.py\", line 1820, in handle_user_exception\n",
            "    reraise(exc_type, exc_value, tb)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/flask/_compat.py\", line 39, in reraise\n",
            "    raise value\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/flask/app.py\", line 1949, in full_dispatch_request\n",
            "    rv = self.dispatch_request()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/flask/app.py\", line 1935, in dispatch_request\n",
            "    return self.view_functions[rule.endpoint](**req.view_args)\n",
            "  File \"<ipython-input-21-8c215dfb9ec1>\", line 42, in word_text\n",
            "    doc_converted = get_docx_text(doc)\n",
            "  File \"<ipython-input-20-1f4c51aa40f8>\", line 2, in get_docx_text\n",
            "    document = zipfile.ZipFile(doc)\n",
            "  File \"/usr/lib/python3.6/zipfile.py\", line 1131, in __init__\n",
            "    self._RealGetContents()\n",
            "  File \"/usr/lib/python3.6/zipfile.py\", line 1198, in _RealGetContents\n",
            "    raise BadZipFile(\"File is not a zip file\")\n",
            "zipfile.BadZipFile: File is not a zip file\n",
            "INFO:werkzeug:127.0.0.1 - - [23/Jan/2020 04:50:29] \"\u001b[1m\u001b[35mPOST /word-text/123 HTTP/1.1\u001b[0m\" 500 -\n",
            "INFO:werkzeug:127.0.0.1 - - [23/Jan/2020 04:50:43] \"\u001b[37mPOST /word-text/123 HTTP/1.1\u001b[0m\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [23/Jan/2020 04:51:25] \"\u001b[37mPOST /word-text/123 HTTP/1.1\u001b[0m\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [23/Jan/2020 04:51:28] \"\u001b[37mPOST /word-text/123 HTTP/1.1\u001b[0m\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [23/Jan/2020 04:52:48] \"\u001b[37mPOST /word-text/123 HTTP/1.1\u001b[0m\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [23/Jan/2020 04:53:03] \"\u001b[37mPOST /word-text/123 HTTP/1.1\u001b[0m\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [23/Jan/2020 04:53:21] \"\u001b[37mPOST /word-text/123 HTTP/1.1\u001b[0m\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [23/Jan/2020 04:53:34] \"\u001b[37mPOST /word-text/123 HTTP/1.1\u001b[0m\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [23/Jan/2020 04:54:14] \"\u001b[37mPOST /word-text/123 HTTP/1.1\u001b[0m\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [23/Jan/2020 04:58:05] \"\u001b[37mPOST /image-text/123 HTTP/1.1\u001b[0m\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [23/Jan/2020 05:01:03] \"\u001b[37mPOST /word-text/123 HTTP/1.1\u001b[0m\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [23/Jan/2020 05:02:01] \"\u001b[37mPOST /word-text/123 HTTP/1.1\u001b[0m\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [23/Jan/2020 05:02:15] \"\u001b[37mPOST /word-text/123 HTTP/1.1\u001b[0m\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [23/Jan/2020 05:07:34] \"\u001b[37mPOST /word-text/123 HTTP/1.1\u001b[0m\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [23/Jan/2020 05:08:34] \"\u001b[37mPOST /word-text/123 HTTP/1.1\u001b[0m\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [23/Jan/2020 05:09:56] \"\u001b[37mPOST /word-text/123 HTTP/1.1\u001b[0m\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [23/Jan/2020 05:11:04] \"\u001b[37mPOST /word-text/123 HTTP/1.1\u001b[0m\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [23/Jan/2020 05:11:23] \"\u001b[37mPOST /word-text/123 HTTP/1.1\u001b[0m\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [23/Jan/2020 05:14:26] \"\u001b[1m\u001b[31mPOST /image-text/123 HTTP/1.1\u001b[0m\" 400 -\n",
            "INFO:werkzeug:127.0.0.1 - - [23/Jan/2020 05:14:59] \"\u001b[37mPOST /image-text/123 HTTP/1.1\u001b[0m\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [23/Jan/2020 05:16:50] \"\u001b[37mPOST /image-text/123 HTTP/1.1\u001b[0m\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [23/Jan/2020 05:17:01] \"\u001b[37mPOST /image-text/123 HTTP/1.1\u001b[0m\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [23/Jan/2020 05:19:36] \"\u001b[37mPOST /image-text/123 HTTP/1.1\u001b[0m\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [23/Jan/2020 05:19:57] \"\u001b[1m\u001b[31mPOST /pdf-text/123 HTTP/1.1\u001b[0m\" 400 -\n",
            "INFO:werkzeug:127.0.0.1 - - [23/Jan/2020 05:20:07] \"\u001b[1m\u001b[31mPOST /pdf-text/123 HTTP/1.1\u001b[0m\" 400 -\n",
            "INFO:werkzeug:127.0.0.1 - - [23/Jan/2020 05:20:22] \"\u001b[37mPOST /pdf-text/123 HTTP/1.1\u001b[0m\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [23/Jan/2020 05:21:20] \"\u001b[37mPOST /pdf-text/123 HTTP/1.1\u001b[0m\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [23/Jan/2020 05:22:39] \"\u001b[37mPOST /pdf-text/123 HTTP/1.1\u001b[0m\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [23/Jan/2020 05:22:52] \"\u001b[37mPOST /pdf-text/123 HTTP/1.1\u001b[0m\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [23/Jan/2020 05:24:32] \"\u001b[37mPOST /pdf-text/123 HTTP/1.1\u001b[0m\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [23/Jan/2020 05:25:49] \"\u001b[37mPOST /pdf-text/123 HTTP/1.1\u001b[0m\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [23/Jan/2020 05:25:50] \"\u001b[37mPOST /pdf-text/123 HTTP/1.1\u001b[0m\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [23/Jan/2020 05:25:53] \"\u001b[37mPOST /pdf-text/123 HTTP/1.1\u001b[0m\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [23/Jan/2020 05:26:49] \"\u001b[37mPOST /pdf-text/123 HTTP/1.1\u001b[0m\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [23/Jan/2020 05:27:35] \"\u001b[37mPOST /pdf-text/123 HTTP/1.1\u001b[0m\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [23/Jan/2020 05:29:59] \"\u001b[37mPOST /word-text/123 HTTP/1.1\u001b[0m\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [23/Jan/2020 05:37:09] \"\u001b[37mPOST /word-text/123 HTTP/1.1\u001b[0m\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [23/Jan/2020 05:38:32] \"\u001b[37mPOST /word-text/123 HTTP/1.1\u001b[0m\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [23/Jan/2020 05:38:51] \"\u001b[37mPOST /word-text/123 HTTP/1.1\u001b[0m\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [23/Jan/2020 05:44:22] \"\u001b[37mPOST /word-text/123 HTTP/1.1\u001b[0m\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [23/Jan/2020 05:46:49] \"\u001b[37mPOST /image-text/123 HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PjqCRhkHhK5M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}